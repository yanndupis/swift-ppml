{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encrypted Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(url: \"https://github.com/tensorflow/swift-models\", .branch(\"master\"))\n",
      "\t\tDatasets\n",
      "\t.package(path: \"/root/swift-ppml/secure_computation/ppmlNB_tensor\")\n",
      "\t\tppmlNB_tensor\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmpn1ucq_ut/swift-install\n",
      "[1/2] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "[2/3] Merging module jupyterInstalledPackages\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location $cwd/swift-install\n",
    "%install '.package(url: \"https://github.com/tensorflow/swift-models\", .branch(\"master\"))' Datasets\n",
    "%install '.package(path: \"$cwd/ppmlNB_tensor\")' ppmlNB_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppmlNB_tensor\n",
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resource: train-images-idx3-ubyte\n",
      "File does not exist locally at expected path: /tmp/MNIST/train-images-idx3-ubyte and must be fetched\n",
      "Fetching URL: http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz...\n",
      "Writing fetched archive to: /tmp/MNIST/train-images-idx3-ubyte.gz\n",
      "Archive saved to: /tmp/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting archive...\n",
      "Loading local data at: /tmp/MNIST/train-images-idx3-ubyte\n",
      "Succesfully loaded resource: train-images-idx3-ubyte\n",
      "Loading resource: train-labels-idx1-ubyte\n",
      "File does not exist locally at expected path: /tmp/MNIST/train-labels-idx1-ubyte and must be fetched\n",
      "Fetching URL: http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz...\n",
      "Writing fetched archive to: /tmp/MNIST/train-labels-idx1-ubyte.gz\n",
      "Archive saved to: /tmp/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting archive...\n",
      "Loading local data at: /tmp/MNIST/train-labels-idx1-ubyte\n",
      "Succesfully loaded resource: train-labels-idx1-ubyte\n",
      "2019-12-31 10:55:45.725065: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\n",
      "2019-12-31 10:55:45.809350: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-12-31 10:55:45.844914: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz\n",
      "2019-12-31 10:55:45.846778: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14664f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-12-31 10:55:45.846831: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2019-12-31 10:55:45.855749: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\n",
      "Loading resource: t10k-images-idx3-ubyte\n",
      "File does not exist locally at expected path: /tmp/MNIST/t10k-images-idx3-ubyte and must be fetched\n",
      "Fetching URL: http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz...\n",
      "Writing fetched archive to: /tmp/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Archive saved to: /tmp/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting archive...\n",
      "Loading local data at: /tmp/MNIST/t10k-images-idx3-ubyte\n",
      "Succesfully loaded resource: t10k-images-idx3-ubyte\n",
      "Loading resource: t10k-labels-idx1-ubyte\n",
      "File does not exist locally at expected path: /tmp/MNIST/t10k-labels-idx1-ubyte and must be fetched\n",
      "Fetching URL: http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz...\n",
      "Writing fetched archive to: /tmp/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Archive saved to: /tmp/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Extracting archive...\n",
      "Loading local data at: /tmp/MNIST/t10k-labels-idx1-ubyte\n",
      "Succesfully loaded resource: t10k-labels-idx1-ubyte\n",
      "2019-12-31 10:55:49.287152: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 31360000 exceeds 10% of system memory.\n",
      "2019-12-31 10:55:49.296633: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 31360000 exceeds 10% of system memory.\n",
      "Beginning training...\n",
      "[Epoch 1] Training Loss: 0.5721164, Training Accuracy: 51786/60032 (0.8626399), Test Loss: 0.3765491, Test Accuracy: 8997/10112 (0.889735)\n",
      "[Epoch 2] Training Loss: 0.3736642, Training Accuracy: 53867/60032 (0.8973048), Test Loss: 0.33808935, Test Accuracy: 9082/10112 (0.89814085)\n",
      "[Epoch 3] Training Loss: 0.34208754, Training Accuracy: 54315/60032 (0.90476745), Test Loss: 0.31377742, Test Accuracy: 9132/10112 (0.9030855)\n",
      "[Epoch 4] Training Loss: 0.32589445, Training Accuracy: 54552/60032 (0.90871537), Test Loss: 0.30354995, Test Accuracy: 9155/10112 (0.90536)\n",
      "[Epoch 5] Training Loss: 0.31517714, Training Accuracy: 54766/60032 (0.91228014), Test Loss: 0.29771915, Test Accuracy: 9185/10112 (0.90832675)\n",
      "[Epoch 6] Training Loss: 0.30779803, Training Accuracy: 54868/60032 (0.91397923), Test Loss: 0.29329404, Test Accuracy: 9181/10112 (0.90793115)\n",
      "[Epoch 7] Training Loss: 0.3018465, Training Accuracy: 54972/60032 (0.91571164), Test Loss: 0.28787988, Test Accuracy: 9202/10112 (0.9100079)\n",
      "[Epoch 8] Training Loss: 0.2974747, Training Accuracy: 55050/60032 (0.9170109), Test Loss: 0.28544813, Test Accuracy: 9207/10112 (0.9105024)\n",
      "[Epoch 9] Training Loss: 0.29331568, Training Accuracy: 55096/60032 (0.9177772), Test Loss: 0.28327274, Test Accuracy: 9203/10112 (0.9101068)\n",
      "[Epoch 10] Training Loss: 0.2902497, Training Accuracy: 55140/60032 (0.91851014), Test Loss: 0.28153732, Test Accuracy: 9202/10112 (0.9100079)\n",
      "[Epoch 11] Training Loss: 0.28739893, Training Accuracy: 55184/60032 (0.9192431), Test Loss: 0.27887937, Test Accuracy: 9202/10112 (0.9100079)\n",
      "[Epoch 12] Training Loss: 0.2850264, Training Accuracy: 55256/60032 (0.9204424), Test Loss: 0.27777016, Test Accuracy: 9221/10112 (0.9118869)\n"
     ]
    }
   ],
   "source": [
    "import Datasets\n",
    "\n",
    "let epochCount = 12\n",
    "let batchSize = 128\n",
    "\n",
    "let dataset = MNIST()\n",
    "\n",
    "var classifier = Sequential {\n",
    "    Flatten<Float>()\n",
    "    Dense<Float>(inputSize: 784, outputSize: 10)\n",
    "}\n",
    "\n",
    "let optimizer = SGD(for: classifier, learningRate: 0.1)\n",
    "\n",
    "print(\"Beginning training...\")\n",
    "\n",
    "struct Statistics {\n",
    "    var correctGuessCount: Int = 0\n",
    "    var totalGuessCount: Int = 0\n",
    "    var totalLoss: Float = 0\n",
    "    var batches: Int = 0\n",
    "}\n",
    "\n",
    "let testBatches = dataset.testDataset.batched(batchSize)\n",
    "\n",
    "// The training loop.\n",
    "for epoch in 1...epochCount {\n",
    "    var trainStats = Statistics()\n",
    "    var testStats = Statistics()\n",
    "    let trainingShuffled = dataset.trainingDataset.shuffled(\n",
    "        sampleCount: dataset.trainingExampleCount, randomSeed: Int64(epoch))\n",
    "\n",
    "    Context.local.learningPhase = .training\n",
    "    for batch in trainingShuffled.batched(batchSize) {\n",
    "        let (labels, images) = (batch.label, batch.data)\n",
    "        // Compute the gradient with respect to the model.\n",
    "        let ùõÅmodel = TensorFlow.gradient(at: classifier) { classifier -> Tensor<Float> in\n",
    "            let ≈∑ = classifier(images)\n",
    "            let correctPredictions = ≈∑.argmax(squeezingAxis: 1) .== labels\n",
    "            trainStats.correctGuessCount += Int(\n",
    "                Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "            trainStats.totalGuessCount += batchSize\n",
    "            let loss = softmaxCrossEntropy(logits: ≈∑, labels: labels)\n",
    "            trainStats.totalLoss += loss.scalarized()\n",
    "            trainStats.batches += 1\n",
    "            return loss\n",
    "        }\n",
    "        // Update the model's differentiable variables along the gradient vector.\n",
    "        optimizer.update(&classifier, along: ùõÅmodel)\n",
    "    }\n",
    "\n",
    "    Context.local.learningPhase = .inference\n",
    "    for batch in testBatches {\n",
    "        let (labels, images) = (batch.label, batch.data)\n",
    "        // Compute loss on test set\n",
    "        let ≈∑ = classifier(images)\n",
    "        let correctPredictions = ≈∑.argmax(squeezingAxis: 1) .== labels\n",
    "        testStats.correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "        testStats.totalGuessCount += batchSize\n",
    "        let loss = softmaxCrossEntropy(logits: ≈∑, labels: labels)\n",
    "        testStats.totalLoss += loss.scalarized()\n",
    "        testStats.batches += 1\n",
    "    }\n",
    "\n",
    "    let trainAccuracy = Float(trainStats.correctGuessCount) / Float(trainStats.totalGuessCount)\n",
    "    let testAccuracy = Float(testStats.correctGuessCount) / Float(testStats.totalGuessCount)\n",
    "    print(\n",
    "        \"\"\"\n",
    "        [Epoch \\(epoch)] \\\n",
    "        Training Loss: \\(trainStats.totalLoss / Float(trainStats.batches)), \\\n",
    "        Training Accuracy: \\(trainStats.correctGuessCount)/\\(trainStats.totalGuessCount) \\\n",
    "        (\\(trainAccuracy)), \\\n",
    "        Test Loss: \\(testStats.totalLoss / Float(testStats.batches)), \\\n",
    "        Test Accuracy: \\(testStats.correctGuessCount)/\\(testStats.totalGuessCount) \\\n",
    "        (\\(testAccuracy))\n",
    "        \"\"\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "let w1 = classifier.layer2.weight\n",
    "let b1 = classifier.layer2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "func get_input() -> (Tensor<Float>, Tensor<Int32>){\n",
    "    let dataset = MNIST()\n",
    "    let trainingShuffled = dataset.trainingDataset.shuffled(\n",
    "        sampleCount: dataset.trainingExampleCount, randomSeed: Int64(1))\n",
    "    var train_iter = trainingShuffled.self.makeIterator()\n",
    "    var image = train_iter.next().unsafelyUnwrapped\n",
    "    return (image.data.reshaped(to: [1, 784]), image.label)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resource: train-images-idx3-ubyte\n",
      "Loading local data at: /tmp/MNIST/train-images-idx3-ubyte\n",
      "Succesfully loaded resource: train-images-idx3-ubyte\n",
      "Loading resource: train-labels-idx1-ubyte\n",
      "Loading local data at: /tmp/MNIST/train-labels-idx1-ubyte\n",
      "Succesfully loaded resource: train-labels-idx1-ubyte\n",
      "2019-12-31 10:56:23.087928: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\n",
      "Loading resource: t10k-images-idx3-ubyte\n",
      "Loading local data at: /tmp/MNIST/t10k-images-idx3-ubyte\n",
      "Succesfully loaded resource: t10k-images-idx3-ubyte\n",
      "Loading resource: t10k-labels-idx1-ubyte\n",
      "Loading local data at: /tmp/MNIST/t10k-labels-idx1-ubyte\n",
      "Succesfully loaded resource: t10k-labels-idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "let (input, label) = get_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypted Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "let input_private = PrivateTensor.from_values(values: Tensor<Double>(input))\n",
    "let w1_private = PrivateTensor.from_values(values: Tensor<Double>(w1))\n",
    "let b1_private = PrivateTensor.from_values(values: Tensor<Double>(b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "let private_prediction = input_private.matmul(y: w1_private).add(y: b1_private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "let decode_prediction = private_prediction.reveal().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
