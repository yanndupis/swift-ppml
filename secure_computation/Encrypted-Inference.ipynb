{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encrypted Inference - Multi-Party Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(url: \"https://github.com/tensorflow/swift-models\", .branch(\"master\"))\n",
      "\t\tDatasets\n",
      "\t.package(path: \"/root/swift-ppml/secure_computation/ppmlNB_encrypted_tensor\")\n",
      "\t\tppmlNB_encrypted_tensor\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmpnpi8qsm3/swift-install\n",
      "[1/2] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "[2/3] Merging module jupyterInstalledPackages\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location $cwd/swift-install\n",
    "%install '.package(url: \"https://github.com/tensorflow/swift-models\", .branch(\"master\"))' Datasets\n",
    "%install '.package(path: \"$cwd/ppmlNB_encrypted_tensor\")' ppmlNB_encrypted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppmlNB_encrypted_tensor\n",
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are performing inferences on encrypted images of digits using multi-party computation protocol. The idea is to split values into shares among several parties (for example 2 servers). One key property of this protocol is that the shares owned by the different parties don't reveal anything about the original values. However what's beautiful about this cryptographic technique is that we can still compute functions (e.g., matmul, add, etc.) on it. The original values get revealed only if the parties decide to combine their shares. MPC assumes that these parties won't collude. However they accept to perform some computations together (e.g., inference on images). \n",
    "\n",
    "You can learn more about encrypted machine learning with MPC from this [fantastic blog post](https://mortendahl.github.io/2017/04/17/private-deep-learning-with-mpc/).\n",
    "\n",
    "In this notebook, we will first publicly train a model classifying images of digits from the MNIST dataset. By public training, we mean that the images and model are not encrypted. Once the model is trained, we will encrypt the images and the model and try to classify them even though they are encrypted :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Public Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we train a model to classify images of digits (0 to 9). For the model, we are using a basic logistic regression. For this toy example, we just implemented MatMul and Add in MPC. However, we could extend the protocol to more complex neural net layers such as Conv2d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resource: train-images-idx3-ubyte\n",
      "Loading resource: train-labels-idx1-ubyte\n",
      "2020-02-09 21:49:18.407220: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\n",
      "2020-02-09 21:49:18.461554: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-02-09 21:49:18.474753: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz\n",
      "2020-02-09 21:49:18.476603: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xde24f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-02-09 21:49:18.476652: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-02-09 21:49:18.478727: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\n",
      "Loading resource: t10k-images-idx3-ubyte\n",
      "Loading resource: t10k-labels-idx1-ubyte\n",
      "Beginning training...\n",
      "[Epoch 1] Training Loss: 0.57188827, Training Accuracy: 51790/60032 (0.86270654), Test Loss: 0.37657738, Test Accuracy: 8992/10112 (0.8892405)\n",
      "[Epoch 2] Training Loss: 0.37366387, Training Accuracy: 53853/60032 (0.89707154), Test Loss: 0.3381326, Test Accuracy: 9082/10112 (0.89814085)\n",
      "[Epoch 3] Training Loss: 0.34208044, Training Accuracy: 54303/60032 (0.90456754), Test Loss: 0.31382644, Test Accuracy: 9135/10112 (0.9033821)\n",
      "[Epoch 4] Training Loss: 0.32588503, Training Accuracy: 54548/60032 (0.9086487), Test Loss: 0.30359608, Test Accuracy: 9159/10112 (0.9057555)\n",
      "[Epoch 5] Training Loss: 0.31516346, Training Accuracy: 54783/60032 (0.9125633), Test Loss: 0.29777935, Test Accuracy: 9182/10112 (0.9080301)\n",
      "[Epoch 6] Training Loss: 0.3077833, Training Accuracy: 54875/60032 (0.9140958), Test Loss: 0.29335612, Test Accuracy: 9181/10112 (0.90793115)\n",
      "[Epoch 7] Training Loss: 0.30183086, Training Accuracy: 54969/60032 (0.91566163), Test Loss: 0.28792754, Test Accuracy: 9204/10112 (0.9102057)\n",
      "[Epoch 8] Training Loss: 0.2974603, Training Accuracy: 55044/60032 (0.916911), Test Loss: 0.28550225, Test Accuracy: 9204/10112 (0.9102057)\n",
      "[Epoch 9] Training Loss: 0.2933012, Training Accuracy: 55091/60032 (0.9176939), Test Loss: 0.28332332, Test Accuracy: 9205/10112 (0.9103046)\n",
      "[Epoch 10] Training Loss: 0.29023543, Training Accuracy: 55148/60032 (0.9186434), Test Loss: 0.28158003, Test Accuracy: 9205/10112 (0.9103046)\n",
      "[Epoch 11] Training Loss: 0.287386, Training Accuracy: 55184/60032 (0.9192431), Test Loss: 0.27892333, Test Accuracy: 9208/10112 (0.91060126)\n",
      "[Epoch 12] Training Loss: 0.28501257, Training Accuracy: 55258/60032 (0.9204757), Test Loss: 0.27781537, Test Accuracy: 9222/10112 (0.91198575)\n"
     ]
    }
   ],
   "source": [
    "import Datasets\n",
    "\n",
    "let epochCount = 12\n",
    "let batchSize = 128\n",
    "\n",
    "let dataset = MNIST()\n",
    "\n",
    "var classifier = Sequential {\n",
    "    Flatten<Float>()\n",
    "    Dense<Float>(inputSize: 784, outputSize: 10)\n",
    "}\n",
    "\n",
    "let optimizer = SGD(for: classifier, learningRate: 0.1)\n",
    "\n",
    "print(\"Beginning training...\")\n",
    "\n",
    "struct Statistics {\n",
    "    var correctGuessCount: Int = 0\n",
    "    var totalGuessCount: Int = 0\n",
    "    var totalLoss: Float = 0\n",
    "    var batches: Int = 0\n",
    "}\n",
    "\n",
    "let testBatches = dataset.testDataset.batched(batchSize)\n",
    "\n",
    "// The training loop.\n",
    "for epoch in 1...epochCount {\n",
    "    var trainStats = Statistics()\n",
    "    var testStats = Statistics()\n",
    "    let trainingShuffled = dataset.trainingDataset.shuffled(\n",
    "        sampleCount: dataset.trainingExampleCount, randomSeed: Int64(epoch))\n",
    "\n",
    "    Context.local.learningPhase = .training\n",
    "    for batch in trainingShuffled.batched(batchSize) {\n",
    "        let (labels, images) = (batch.label, batch.data)\n",
    "        // Compute the gradient with respect to the model.\n",
    "        let ùõÅmodel = TensorFlow.gradient(at: classifier) { classifier -> Tensor<Float> in\n",
    "            let ≈∑ = classifier(images)\n",
    "            let correctPredictions = ≈∑.argmax(squeezingAxis: 1) .== labels\n",
    "            trainStats.correctGuessCount += Int(\n",
    "                Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "            trainStats.totalGuessCount += batchSize\n",
    "            let loss = softmaxCrossEntropy(logits: ≈∑, labels: labels)\n",
    "            trainStats.totalLoss += loss.scalarized()\n",
    "            trainStats.batches += 1\n",
    "            return loss\n",
    "        }\n",
    "        // Update the model's differentiable variables along the gradient vector.\n",
    "        optimizer.update(&classifier, along: ùõÅmodel)\n",
    "    }\n",
    "\n",
    "    Context.local.learningPhase = .inference\n",
    "    for batch in testBatches {\n",
    "        let (labels, images) = (batch.label, batch.data)\n",
    "        // Compute loss on test set\n",
    "        let ≈∑ = classifier(images)\n",
    "        let correctPredictions = ≈∑.argmax(squeezingAxis: 1) .== labels\n",
    "        testStats.correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "        testStats.totalGuessCount += batchSize\n",
    "        let loss = softmaxCrossEntropy(logits: ≈∑, labels: labels)\n",
    "        testStats.totalLoss += loss.scalarized()\n",
    "        testStats.batches += 1\n",
    "    }\n",
    "\n",
    "    let trainAccuracy = Float(trainStats.correctGuessCount) / Float(trainStats.totalGuessCount)\n",
    "    let testAccuracy = Float(testStats.correctGuessCount) / Float(testStats.totalGuessCount)\n",
    "    print(\n",
    "        \"\"\"\n",
    "        [Epoch \\(epoch)] \\\n",
    "        Training Loss: \\(trainStats.totalLoss / Float(trainStats.batches)), \\\n",
    "        Training Accuracy: \\(trainStats.correctGuessCount)/\\(trainStats.totalGuessCount) \\\n",
    "        (\\(trainAccuracy)), \\\n",
    "        Test Loss: \\(testStats.totalLoss / Float(testStats.batches)), \\\n",
    "        Test Accuracy: \\(testStats.correctGuessCount)/\\(testStats.totalGuessCount) \\\n",
    "        (\\(testAccuracy))\n",
    "        \"\"\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this basic model acheives 91.1% accuracy on the testing set. We could definitely improve the accuracy with a more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Save Model Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, let's save its weights to later perform encrypted inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Extract weights\n",
    "let w1 = classifier.layer2.weight\n",
    "let b1 = classifier.layer2.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just extract several images from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "func get_input(_ nb_input: Int) -> (Tensor<Float>, Tensor<Int32>){\n",
    "    let dataset = MNIST()\n",
    "    let trainingShuffled = dataset.trainingDataset.shuffled(\n",
    "        sampleCount: dataset.trainingExampleCount, \n",
    "        randomSeed: Int64(1)).batched(nb_input)\n",
    "    var train_iter = trainingShuffled.self.makeIterator()\n",
    "    var image = train_iter.next().unsafelyUnwrapped\n",
    "    return (image.data.reshaped(to: [nb_input, 784]), image.label)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resource: train-images-idx3-ubyte\n",
      "Loading resource: train-labels-idx1-ubyte\n",
      "2020-02-09 21:49:50.357843: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\n",
      "2020-02-09 21:49:50.434752: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\n",
      "Loading resource: t10k-images-idx3-ubyte\n",
      "Loading resource: t10k-labels-idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "let (input, label) = get_input(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Encrypted Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Our model is ready, so let's perform some private predictions. To encrypt an image, we can convert the tensor into a PrivateTensor as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "let encryped_images = PrivateTensor.from_values(values: input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‚ñø PrivateTensor\n",
       "  - share0 : [[-6787589838563964911,  6448897555809465334,  7934375839428403173, ...,\n",
       "   8672702744847897347, -7765916615583691251,  1436726397468966556],\n",
       " [ 3863737563595048021,   -15318943555949504,  6405016834740266553, ...,\n",
       "  -4339131960208094544, -4073941091161145433,  6667856077130869403],\n",
       " [-4396048434353189395, -2984543475000313945, -4412639684622742885, ...,\n",
       "  -7981350163169210170,  3228171541547781169,  5744873139302189729]]\n",
       "  - share1 : [[ 6787589838563964911, -6448897555809465334, -7934375839428403173, ...,\n",
       "  -8672702744847897347,  7765916615583691251, -1436726397468966556],\n",
       " [-3863737563595048021,    15318943555949504, -6405016834740266553, ...,\n",
       "   4339131960208094544,  4073941091161145433, -6667856077130869403],\n",
       " [ 4396048434353189395,  2984543475000313945,  4412639684622742885, ...,\n",
       "   7981350163169210170, -3228171541547781169, -5744873139302189729]]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encryped_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, once the original tensor (image) is transformed into a PrivateTensor, its values are split into shares among two parties. Again one of the key property of MPC is that these shares are not revealing about the original values. It would be impossible for each party if the image is a 1 or 3 or 9 etc. For this towy example, the shares are on the same machine, but in practice they could be on different servers. \n",
    "\n",
    "Now we compute our logistic regression on the encrypted images. It's just a MatMul and an addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "func private_prediction(input: Tensor<Float>) -> PrivateTensor{\n",
    "    let input_private = PrivateTensor.from_values(values: input)\n",
    "    let w1_private = PrivateTensor.from_values(values: w1)\n",
    "    let b1_private = PrivateTensor.from_values(values: b1)\n",
    "    let private_pred = add(x: matmul(x: input_private, y: w1_private), y: b1_private)\n",
    "    return private_pred\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are also encrypting the model (`PrivateTensor.from_values`). So if we deploy this model into the cloud, even the model would be encrypted.\n",
    "\n",
    "Now, let's perform some private predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private prediction result: 0. Expected prediction: 0\r\n",
      "Private prediction result: 5. Expected prediction: 5\r\n",
      "Private prediction result: 1. Expected prediction: 1\r\n"
     ]
    }
   ],
   "source": [
    "for i in 0...2 {\n",
    "    var private_output = private_prediction(input: input[i].reshaped(to: [1,784]))\n",
    "    var decode_prediction = private_output.reveal().decode()\n",
    "    var private_class = decode_prediction.argmax(squeezingAxis: 1)[0]\n",
    "    var exp_class = label[i]\n",
    "    print(\"Private prediction result: \\(private_class). Expected prediction: \\(exp_class)\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, we are abale to perform predictions on enrypted data with an encrypted model. At no point during this computation are we decrypting these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
